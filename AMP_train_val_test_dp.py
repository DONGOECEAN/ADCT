"""
- åœ¨çº¿ 28â†’224 æ’å€¼ã€AG ç”Ÿæˆ
- Ishihara PNG ç›®å½•è¯»å– + æ¯ç±»é™é‡é‡‡æ ·ï¼ˆå¯¹é½è®ºæ–‡ï¼štrain 1000 / test 200ï¼‰
- ä¸‰ç§ç­–ç•¥ï¼šS0ï¼ˆä»…Ishï¼‰ï¼ŒS1ï¼ˆIsh+AGï¼‰ï¼ŒS2ï¼ˆS1 + DeepAugment + AugMixï¼‰
- éªŒè¯é›†ï¼šIsh_valï¼ˆæ¯ç±»100ï¼‰ + AG6(hor/ver) ä½œä¸ºä»£ç† OODï¼›ç”¨å…¶ mean_acc é€‰æ‹© best.ckpt
- è®­ç»ƒä¸­æ¯è½®ä»ç„¶æµ‹ 6 ä¸ªæµ‹è¯•é›†ï¼ˆä»…è®°å½•æ›²çº¿ï¼Œä¸ç”¨äºé€‰æ‹©ï¼‰
- è®­ç»ƒç»“æŸååŠ è½½ best.ckpt åœ¨ 6 ä¸ªæµ‹è¯•é›†åšä¸€æ¬¡â€œæœ€ç»ˆè¯„æµ‹â€ï¼Œè¾“å‡º acc/NLL/ECE/PRF1/CMï¼ˆå¯é€‰AUROCï¼‰
"""
import os, time, argparse, random
import torch, torch.nn as nn, torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.models as models
from torch.utils.checkpoint import checkpoint
from Ishihara_data import (
    build_ishihara_png, build_ishihara_train_val, collate_and_to224,
    mnist_train_dataset, mnist_test_dataset, normalize_imagenet)
from Abutting_grating_illusion import ag_distort_224, transform_224
from utils_legacy import (augmix_batch, jsd_loss, Noise2NetDA, save_image,
    reliability_points, negative_log_likelihood, expected_calibration_error,
    confusion_matrix_from_logits, prf1_from_confusion_matrix, auroc_one_vs_rest,
    save_confusion_matrix_png, save_matrix_csv)

from torch.cuda.amp import autocast, GradScaler

# ---- DataParallel helper ----
def _unwrap(m):
    """Return underlying module when wrapped by nn.DataParallel; otherwise return as-is."""
    return m.module if isinstance(m, nn.DataParallel) else m


# ä¸¤ä¸ªç‹¬ç«‹å¼€å…³ï¼šè®­ç»ƒæœŸ AMPï¼›è¯„ä¼°æœŸ AMPï¼ˆé»˜è®¤è¯„ä¼°ä¸å¼€ï¼Œç¡®ä¿å¯æ¯”æ€§ï¼‰
AMP_TRAIN = False
AMP_EVAL  = False


TESTSETS = ["original","Ishihara","hor4","hor8","ver4","ver8"]
KEY_EVAL = ["Ishihara","hor4","hor8","ver4","ver8"]


def _should_save_epoch(epoch: int, every: int) -> bool:
    if every <= 0:
        return epoch == 0
    return (epoch % every) == 0

def _has_attr(obj, name: str) -> bool:
    return hasattr(obj, name)

def build_backbone(name: str, num_classes: int, pretrained: bool=True):
    """
    å…¼å®¹è€/æ–° torchvisionï¼š
    - æ–°APIï¼šweights=XXX_Weights.IMAGENET1K_*
    - æ—§APIï¼špretrained=True/False
    å¯¹äºç¯å¢ƒé‡Œæ²¡æœ‰çš„æ¨¡å‹ï¼ˆå¦‚è€ç‰ˆæœ¬æ—  convnext/efficientnetï¼‰ï¼Œè‡ªåŠ¨å›é€€æˆ–æŠ¥æ¸…æ™°é”™è¯¯ã€‚
    """
    n = name.lower()

    def _resnet50():
        if _has_attr(models, "ResNet50_Weights"):
            wt = models.ResNet50_Weights.IMAGENET1K_V2 if pretrained else None
            m = models.resnet50(weights=wt)
        else:
            m = models.resnet50(pretrained=pretrained)
        in_f = m.fc.in_features
        m.fc = nn.Linear(in_f, num_classes)
        return m

    def _resnet101():
        if _has_attr(models, "ResNet101_Weights"):
            wt = models.ResNet101_Weights.IMAGENET1K_V2 if pretrained else None
            m = models.resnet101(weights=wt)
        else:
            m = models.resnet101(pretrained=pretrained)
        in_f = m.fc.in_features
        m.fc = nn.Linear(in_f, num_classes)
        return m

    def _inception_v3():
        if _has_attr(models, "Inception_V3_Weights"):
            wt = models.Inception_V3_Weights.IMAGENET1K_V1 if pretrained else None
            m = models.inception_v3(weights=wt, aux_logits=False)
        else:
            m = models.inception_v3(pretrained=pretrained, aux_logits=False)
        in_f = m.fc.in_features
        m.fc = nn.Linear(in_f, num_classes)
        return m

    def _convnext_tiny():
        if not _has_attr(models, "convnext_tiny"):
            raise RuntimeError("convnext_tiny åœ¨ä½ å½“å‰ torchvision ç‰ˆæœ¬é‡Œä¸å¯ç”¨ï¼›è¯·ç”¨ --model_name resnet50 æˆ–å‡çº§ torchvisionã€‚")
        if _has_attr(models, "ConvNeXt_Tiny_Weights"):
            wt = models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1 if pretrained else None
            m = models.convnext_tiny(weights=wt)
        else:
            m = models.convnext_tiny(pretrained=pretrained)
        in_f = m.classifier[2].in_features
        m.classifier[2] = nn.Linear(in_f, num_classes)
        return m

    def _efficientnet_b4():
        if not _has_attr(models, "efficientnet_b4"):
            raise RuntimeError("efficientnet_b4 åœ¨ä½ å½“å‰ torchvision ç‰ˆæœ¬é‡Œä¸å¯ç”¨ï¼›è¯·ç”¨ --model_name resnet50 æˆ–å‡çº§ torchvisionã€‚")
        if _has_attr(models, "EfficientNet_B4_Weights"):
            wt = models.EfficientNet_B4_Weights.IMAGENET1K_V1 if pretrained else None
            m = models.efficientnet_b4(weights=wt)
        else:
            m = models.efficientnet_b4(pretrained=pretrained)
        in_f = m.classifier[1].in_features
        m.classifier[1] = nn.Linear(in_f, num_classes)
        return m

    # è·¯ç”±
    if n in ["resnet50","r50"]:
        return _resnet50()
    elif n in ["resnet101","r101"]:
        return _resnet101()
    elif n in ["inception_v3","inception"]:
        return _inception_v3()
    elif n in ["convnext_t","convnext_tiny","convnext"]:
        return _convnext_tiny()
    elif n in ["efficientnet_b4","effb4","eb4"]:
        return _efficientnet_b4()
    else:
        # é»˜è®¤å›é€€åˆ° resnet18ï¼Œä¹Ÿåšæ–°æ—§APIå…¼å®¹
        if _has_attr(models, "ResNet18_Weights"):
            wt = models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None
            m = models.resnet18(weights=wt)
        else:
            m = models.resnet18(pretrained=pretrained)
        in_f = m.fc.in_features
        m.fc = nn.Linear(in_f, num_classes)
        return m


def _apply_augmix_then_norm(x_raw, model, targets, criterion, jsd_weight,da_module=None, da_eps_min=None, da_eps_max=None,return_fed=False,
                            use_ckpt=False):
    """
    x_raw: [0,1] ç©ºé—´çš„å›¾åƒå¼ é‡ï¼ˆå·²åš 28->224, AG ç­‰åƒç´ åŸŸå¤„ç†ï¼‰
    æµç¨‹ï¼šAugMix(aug1,aug2) -> Normalize -> (DA on aug1/aug2) -> forward
         clean:   Normalize -> (no DA) -> forward
    """
    # 1) åƒç´ åŸŸ AugMix
    x_aug1 = augmix_batch(x_raw.clone())
    x_aug2 = augmix_batch(x_raw.clone())

    # 2) å½’ä¸€åŒ–
    x_clean = normalize_imagenet(x_raw)
    x_aug1 = normalize_imagenet(x_aug1)
    x_aug2 = normalize_imagenet(x_aug2)

    # 3) ä»…åœ¨ AugMix åˆ†æ”¯ä¸ŠåŠ  DeepAugmentï¼ˆNoise2Net-DAï¼‰
    if da_module is not None:
        _emin = 0.375 if da_eps_min is None else da_eps_min
        _emax = 0.75 if da_eps_max is None else da_eps_max
        x_aug1 = da_module(x_aug1, eps_min=_emin, eps_max=_emax)
        x_aug2 = da_module(x_aug2, eps_min=_emin, eps_max=_emax)
        # æ³¨æ„ï¼šclean ä¸åŠ  DAï¼Œä¿æŒ CE çš„â€œå¹²å‡€ç›‘ç£â€

    # 4) å‰å‘ & æŸå¤±
    def _run(x):
        return model(x)

    if use_ckpt:
        x_clean = x_clean.detach().requires_grad_(True)
        x_aug1 = x_aug1.detach().requires_grad_(True)
        x_aug2 = x_aug2.detach().requires_grad_(True)
        logits_clean = checkpoint(_run, x_clean)
        logits_aug1 = checkpoint(_run, x_aug1)
        logits_aug2 = checkpoint(_run, x_aug2)
    else:
        logits_clean = model(x_clean)
        logits_aug1 = model(x_aug1)
        logits_aug2 = model(x_aug2)

    loss_ce  = criterion(logits_clean, targets)
    loss_jsd = jsd_weight * jsd_loss(logits_clean, logits_aug1, logits_aug2)
    loss = loss_ce + loss_jsd

    if return_fed:
        # å¯é€‰ï¼šè¿”å›â€œæœ€ç»ˆé€å…¥æ¨¡å‹â€çš„ä¸‰è·¯è¾“å…¥ï¼Œæ–¹ä¾¿ä½ ä¿å­˜æ ¸éªŒ
        return loss, dict(clean=x_clean.detach(), aug1=x_aug1.detach(), aug2=x_aug2.detach())
    return loss

def evaluate(model, loader, device, name, epoch, save_pic: bool):
    model.eval(); correct=0; total=0; logits_all=[]; labels_all=[]
    with torch.no_grad():
        for i,(x,y) in enumerate(loader):
            x = x.to(device, non_blocking=True); y = y.to(device, non_blocking=True)
            with autocast(enabled=AMP_EVAL):
                logits = model(x)
            if save_pic and i==2:
                save_image(x[2], f"saved_samples/{name}_ep{epoch}_batch3_img3.png")
                print(f"[è¯„ä¼°:{name}] ç¬¬3æ‰¹ç¬¬3å¼ å›¾å·²ä¿å­˜ï¼Œmean={x.mean():.4f}, std={x.std():.4f}")
            preds = logits.argmax(1); total += y.size(0); correct += (preds==y).sum().item()
            logits_all.append(logits.cpu()); labels_all.append(y.cpu())
    logits=torch.cat(logits_all); labels=torch.cat(labels_all)
    acc = correct/total; nll = negative_log_likelihood(logits, labels).item()
    ece = expected_calibration_error(logits, labels, n_bins=15)
    xs, ys = reliability_points(logits, labels, n_bins=15)
    return acc, nll, ece, xs, ys

def main():
    parser = argparse.ArgumentParser()
    # å°½é‡å…¼å®¹ä½ åŸå…ˆå‚æ•°å
    parser.add_argument('-model_name', '--model_name', default='resnet50', help='éª¨å¹²ç½‘ç»œåç§°')
    parser.add_argument('-device', '--device', default='cuda:0')
    parser.add_argument('-epochs', '--epochs', type=int, default=100)
    parser.add_argument('-batch_size', '--batch_size', type=int, default=128)
    parser.add_argument('-num_workers', '--num_workers', type=int, default=8)
    parser.add_argument('-seed', '--seed', type=int, default=0)
    parser.add_argument('--pretrained', action='store_true', help='æ˜¯å¦åŠ è½½ImageNeté¢„è®­ç»ƒæƒé‡')
    parser.add_argument('--opt', choices=['adamw','sgd'], default='adamw')
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--wd', type=float, default=5e-2)

    # æ•°æ®ä¸é‡‡æ ·
    parser.add_argument('--mnist_root', default='./datasets')
    parser.add_argument('--ish_root',   default='./datasets/png224')
    parser.add_argument('--cap_train', type=int, default=1000, help='Ishiharaæ¯ç±»ä¸Šé™ï¼ˆè®ºæ–‡å¯¹é½ï¼‰')
    parser.add_argument('--cap_test',  type=int, default=200)
    parser.add_argument('--download', action='store_true', help='è‹¥datasetsç›®å½•ç¼ºå¤±MNISTåˆ™ä¸‹è½½')
    # éªŒè¯ä¸é€‰æ‹©
    parser.add_argument('--use_val_selection', action='store_true', default=True, help='ç”¨éªŒè¯é›†é€‰æ‹©best_epoch')
    parser.add_argument('--val_cap_per_class', type=int, default=100, help='Ishiharaæ¯ç±»éªŒè¯æ ·æœ¬æ•°')
    parser.add_argument('--min_delta', type=float, default=0.0, help='bestæå‡é˜ˆå€¼ï¼ˆé˜²æŠ–ï¼‰')
    parser.add_argument('--test_each_epoch', action='store_true', default=True, help='æ¯ä¸ªepochéƒ½åœ¨6ä¸ªæµ‹è¯•é›†ä¸Šè¯„æµ‹ï¼ˆä»…è®°å½•ï¼Œä¸ç”¨äºé€‰æ‹©ï¼‰')
    parser.add_argument('--final_test_only', action='store_true', default=False, help='è‹¥å¼€åˆ™è®­ç»ƒæœŸä¸è·‘æµ‹è¯•é›†ï¼Œæœ€åä¸€æ¬¡ç”¨best.ckptè·‘æµ‹è¯•')
    parser.add_argument('--compute_auroc', action='store_true', help='æœ€ç»ˆè¯„æµ‹æ—¶è®¡ç®—AUROC(OVR macro)')
    parser.add_argument('--final_results_file', default='final_results.csv', help='æœ€ç»ˆè¯„æµ‹CSVæ–‡ä»¶åï¼ˆé»˜è®¤ final_results.csvï¼‰')

    # ç­–ç•¥ä¸å¢å¼º
    parser.add_argument('--strategy', choices=['S0','S1','S2'], default='S2')
    parser.add_argument('--augmix', action='store_true')
    parser.add_argument('--augmix_jsd', type=float, default=12.0)
    parser.add_argument('--deepaugment', action='store_true')
    parser.add_argument('--da_blocks', type=int, default=2)
    parser.add_argument('--da_eps_min', type=float, default=0.375)
    parser.add_argument('--da_eps_max', type=float, default=0.75)
    parser.add_argument('--amp_train', action='store_true', default=True,
                        help='è®­ç»ƒæœŸå¯ç”¨æ··åˆç²¾åº¦ï¼ˆS1/S2 ç”Ÿæ•ˆï¼ŒS0 å›ºå®šå…³é—­ï¼‰')
    parser.add_argument('--amp_eval', action='store_true', default=False,
                        help='è¯„ä¼°æœŸå¯ç”¨æ··åˆç²¾åº¦ï¼ˆé»˜è®¤å…³é—­ä»¥ä¿è¯å„ç­–ç•¥å¯æ¯”ï¼‰')
    parser.add_argument('--use_ckpt', action='store_true',
                        help='åœ¨ S2 çš„ä¸‰è·¯å‰å‘ä¸Šå¯ç”¨ gradient checkpointingï¼ˆé™æ˜¾å­˜ï¼Œç•¥æ…¢ï¼‰')
    # åœ¨ç°æœ‰ parser.add_argument ä»¬åé¢åŠ ä¸€è¡Œ
    parser.add_argument('--save_eval_imgs_every', type=int, default=1,
                        help='0=åªåœ¨ç¬¬0ä¸ªepochä¿å­˜ï¼›N=æ¯éš”Nä¸ªepochä¿å­˜ä¸€æ¬¡ï¼ˆå«ç¬¬0ä¸ªï¼‰')

    # ç»“æœ
    parser.add_argument('--results_file', default='results.csv')
    parser.add_argument('--dp', action='store_true', help='Use nn.DataParallel across all available GPUs on this machine')

    args = parser.parse_args()
    print(f"ğŸ² seed={args.seed}")
    global AMP_TRAIN, AMP_EVAL
    AMP_TRAIN = bool(args.amp_train and args.strategy in ['S1', 'S2'] and torch.cuda.is_available())
    AMP_EVAL = bool(args.amp_eval and torch.cuda.is_available())
    scaler = GradScaler(enabled=AMP_TRAIN)

    if args.strategy == 'S0':
        args.augmix = False; args.deepaugment = False
    elif args.strategy == 'S1':
        args.augmix = False; args.deepaugment = False
    elif args.strategy == 'S2':
        args.augmix = True; args.deepaugment = True

    # å›ºå®šéšæœºç§å­
    torch.manual_seed(args.seed); random.seed(args.seed)
    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
    torch.backends.cudnn.benchmark = True

    # æ¨¡å‹ä¸ä¼˜åŒ–å™¨
    model = build_backbone(args.model_name, num_classes=10, pretrained=args.pretrained).to(device)
    # â˜… Enable DataParallel across available GPUs on this machine if requested
    if args.dp and torch.cuda.is_available() and torch.cuda.device_count() > 1:
        device_ids = list(range(torch.cuda.device_count()))
        print(f"ğŸ§© å¯ç”¨ DataParallelï¼š{torch.cuda.device_count()} x GPUï¼Œdevice_ids={device_ids}ï¼Œä¸»å¡=cuda:0")
        model = nn.DataParallel(model, device_ids=device_ids).to(device)

    print("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼š", args.model_name)
    print(model)
    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.wd) if args.opt=='adamw' \
        else optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=args.wd)
    criterion = nn.CrossEntropyLoss()

    # === Ishihara è®­ç»ƒ/éªŒè¯ä¸¥æ ¼ä¸é‡å  ===
    ish_train, ish_val = build_ishihara_train_val(
        root=args.ish_root, plates=[2,3,5,6,7,9],
        cap_train=args.cap_train, cap_val=args.val_cap_per_class, seed=args.seed
    )
    ish_loader = DataLoader(ish_train, batch_size=args.batch_size, shuffle=True,
                            num_workers=args.num_workers, pin_memory=True)
    print(f"âœ… Ishihara è®­ç»ƒé›†å°±ç»ªï¼ˆæ¯ç±»{args.cap_train}ï¼‰ï¼ŒéªŒè¯é›†å°±ç»ªï¼ˆæ¯ç±»{args.val_cap_per_class}ï¼‰ã€‚")
    mnist_train = mnist_train_dataset(root=args.mnist_root, download=args.download)

    # æµ‹è¯•é›†ï¼ˆå›ºå®šï¼šori224ã€Ish p{2,4,8}ã€AGå››å¥—ï¼‰
    print("âŒ› æ­£åœ¨æ„å»º 6 ä¸ªæµ‹è¯•åŠ è½½å™¨...")
    test_loaders = {}
    test_loaders["original"] = DataLoader(
        mnist_test_dataset(args.mnist_root, download=args.download),
        batch_size=64, shuffle=False, num_workers=args.num_workers, pin_memory=True,
        collate_fn=lambda b: collate_and_to224(b)
    )
    ish_test = build_ishihara_png(args.ish_root, split='test', plates=[2,4,8],
                                  cap_per_class=args.cap_test, seed=args.seed)
    test_loaders["Ishihara"] = DataLoader(ish_test, batch_size=64, shuffle=False,
                                          num_workers=args.num_workers, pin_memory=True,
                                          collate_fn=lambda b: collate_and_to224(b))
    from functools import partial
    def collate_mnist_ag(batch, interval:int, direction:str):
        imgs, labels = zip(*batch)
        x = torch.stack(imgs, dim=0)  # [B,1,28,28]
        dir_vec = (1,0) if direction=='hor' else (0,1)
        x = ag_distort_224(x, threshold=0.5, interval=interval, phase=interval//2, direction=dir_vec)
        x = normalize_imagenet(x.float())
        y = torch.tensor(labels, dtype=torch.long); return x, y

    for name, spec in {
        "hor4": dict(interval=4, direction='hor'),
        "hor8": dict(interval=8, direction='hor'),
        "ver4": dict(interval=4, direction='ver'),
        "ver8": dict(interval=8, direction='ver'),
    }.items():
        test_loaders[name] = DataLoader(
            mnist_test_dataset(args.mnist_root, download=args.download),
            batch_size=64, shuffle=False, num_workers=args.num_workers, pin_memory=True,
            collate_fn=partial(collate_mnist_ag, interval=spec['interval'], direction=spec['direction'])
        )
    print("âœ… æµ‹è¯•åŠ è½½å™¨å°±ç»ªã€‚")

    # === éªŒè¯ï¼šAG6ï¼ˆhor/verï¼‰ä½œä¸ºä»£ç† OODï¼ˆé¿å…ä¸æµ‹è¯• 4/8 é‡å ï¼‰===
    ag6_hor_val_loader = DataLoader(
        mnist_test_dataset(args.mnist_root, download=args.download),
        batch_size=64, shuffle=False, num_workers=args.num_workers, pin_memory=True,
        collate_fn=partial(collate_mnist_ag, interval=6, direction='hor')
    )
    ag6_ver_val_loader = DataLoader(
        mnist_test_dataset(args.mnist_root, download=args.download),
        batch_size=64, shuffle=False, num_workers=args.num_workers, pin_memory=True,
        collate_fn=partial(collate_mnist_ag, interval=6, direction='ver')
    )

    def _eval_loader_acc(model, loader, device, name, epoch,
                     save_val_sample=False):
        model.eval(); correct=0; total=0
        with torch.no_grad():
            for i, (x, y) in enumerate(loader):
                x = x.to(device, non_blocking=True)
                y = y.to(device, non_blocking=True)
                with autocast(enabled=AMP_EVAL):
                    logits = model(x)
                preds = logits.argmax(1)
                total += y.size(0)
                correct += (preds == y).sum().item()
                if save_val_sample and i == 2:
                    save_image(x[2], f"saved_samples/{name}_ep{epoch}_batch3_img3_input.png")
                if (i + 1) % 50 == 0:
                    bs = x.size(0)
                    print(f"[è¯„ä¼°:{name}] å·²å¤„ç† {(i + 1) * bs} å¼ ")
        acc = correct / total if total > 0 else 0.0
        print(f" éªŒè¯é›†[Val] {name}: acc={acc:.4f}")
        return acc

    # å¢å¼ºæ¨¡å—
    da_module = Noise2NetDA(blocks=args.da_blocks).to(device) if args.deepaugment else None
    os.makedirs("saved_samples", exist_ok=True)

    # è®­ç»ƒå¾ªç¯
    results_rows = []
    best_metric = -1e9
    best_epoch_sel = -1
    best_subset_mean = -1.0; best_epoch = -1
    print("ğŸš€ å¼€å§‹è®­ç»ƒï¼ç­–ç•¥:", args.strategy)
    print(
        f"[cfg] model={args.model_name}, strategy={args.strategy},seed={args.seed}, "
        f"augmix={args.augmix}, deepaugment={args.deepaugment}, "
        f"use_ckpt={getattr(args, 'use_ckpt', False)}, "
        f"amp_train={AMP_TRAIN}, amp_eval={AMP_EVAL}, "
        f"da_eps=[{args.da_eps_min:.3f},{args.da_eps_max:.3f}], "
        f"batch_size={args.batch_size}, device={args.device}"
    )

    for epoch in range(args.epochs):
        SAVE_THIS_EPOCH = _should_save_epoch(epoch, args.save_eval_imgs_every)
        # æœ¬è½®è®¡æ•°å™¨
        train_seen_epoch = 0
        # test_seen_epoch / val_seen_epoch åœ¨å„è‡ªé˜¶æ®µé‡Œç»Ÿè®¡

        model.train(); running_loss=0.0; total_updates=0
        t0 = time.time()
        mnist_loader = DataLoader(mnist_train, batch_size=args.batch_size, shuffle=True,
                                  num_workers=args.num_workers, pin_memory=True)

        def sample_ag(x28):
            interval = random.choice([4,8]); direction = random.choice(['hor','ver'])
            dir_vec = (1,0) if direction=='hor' else (0,1)
            return ag_distort_224(x28, threshold=0.5, interval=interval, phase=interval//2, direction=dir_vec)

        if args.strategy == 'S0':
            assert (not args.augmix) and (not args.deepaugment), "S0 ä¸èƒ½å¼€å¯ AugMix / DeepAugment"
            for i,(xb_i,yb_i) in enumerate(ish_loader):
                xi_raw = xb_i.to(device, non_blocking=True).float()
                yi = yb_i.to(device, non_blocking=True)
                train_seen_epoch += yi.size(0)
                if i==0 and epoch==0:
                    save_image(xi_raw[0], f"saved_samples/æœªå½’ä¸€åŒ–ep{epoch}_ish_clean.png")
                    print("ğŸ–¼ï¸ å·²ä¿å­˜ Ishihara æ ·ä¾‹å›¾ï¼šsaved_samples/æœªå½’ä¸€åŒ–ep0_ish_clean.png")
                if args.augmix:
                    loss_i, fed_i = _apply_augmix_then_norm(
                        xi_raw, model, yi, criterion, args.augmix_jsd,
                        da_module=da_module, da_eps_min=args.da_eps_min, da_eps_max=args.da_eps_max,return_fed=True
                    )
                    if i == 0 and epoch == 0:
                        save_image(fed_i["clean"][0], f"saved_samples/train_ep{epoch}_ish_input.png")
                else:
                    xi = normalize_imagenet(xi_raw)
                    if da_module is not None:
                        xi = da_module(xi)
                    if i == 0 and epoch == 0:
                        save_image(xi[0].detach().cpu(), f"saved_samples/train_ep{epoch}_ish_input.png")
                        print(f"[dump] s0ç­–ç•¥ï¼šsaved_samples/train_ep{epoch}_ish_input.png")
                    logits = model(xi)
                    loss_i = criterion(logits, yi)

                optimizer.zero_grad(set_to_none=True); loss_i.backward(); optimizer.step()
                running_loss += float(loss_i.item()); total_updates += 1
                if (i + 1) % 50 == 0:
                    seen = (i + 1) * args.batch_size
                    print(f"[è®­ç»ƒ:S0] epoch={epoch} å·²å¤„ç† {seen} å¼  Ishihara å›¾åƒ")
        else:
            for batch_idx, ((xb_i,yb_i),(xb_m,yb_m)) in enumerate(zip(ish_loader, mnist_loader)):
                # Ishihara
                xi_raw = xb_i.to(device, non_blocking=True).float()
                yi = yb_i.to(device, non_blocking=True)
                train_seen_epoch += yi.size(0)  # â† Ishihara è®¡æ•°
                # Ishihara æ”¯è·¯
                if args.strategy == 'S2' and args.augmix:
                    with autocast(enabled=AMP_TRAIN):
                        out = _apply_augmix_then_norm(
                        xi_raw, model, yi, criterion, args.augmix_jsd,
                        da_module=da_module,da_eps_min=args.da_eps_min, da_eps_max=args.da_eps_max,
                        return_fed=(epoch == 0 and batch_idx == 0),use_ckpt=args.use_ckpt
                    )

                    if isinstance(out, tuple):
                        loss_i, fed = out
                        if epoch == 0 and batch_idx == 0:
                            save_image(fed["clean"][0], f"saved_samples/train_ep{epoch}_ish_clean_input.png")
                            save_image(fed["aug1"][0], f"saved_samples/train_ep{epoch}_ish_aug1_input.png")
                            save_image(fed["aug2"][0], f"saved_samples/train_ep{epoch}_ish_aug2_input.png")
                    else:
                        loss_i = out
                else:
                    # S0/S1 èµ°è¿™é‡Œï¼šåªæœ‰â€œå•è·¯æœ€ç»ˆè¾“å…¥â€
                    xi = normalize_imagenet(xi_raw)
                    if da_module is not None:
                        xi = da_module(xi)  # æ³¨ï¼šåœ¨ S0/S1 ä¸­ da_module æœ¬æ¥å°±æ˜¯ None
                    if batch_idx == 0 and epoch == 0:
                        save_image(xi[0].detach().cpu(), f"saved_samples/train_ep{epoch}_ish_input.png")
                        print(f"[dump] s1ç­–ç•¥,saved_samples/train_ep{epoch}_ish_input.png")
                    with autocast(enabled=AMP_TRAIN):
                        logits = model(xi)
                        loss_i = criterion(logits, yi)

                # ---------------- [II] å…ˆå›ä¼  Ishï¼ˆé‡Šæ”¾è¿™æ¡å¤§å›¾ï¼‰ ----------------
                optimizer.zero_grad(set_to_none=True)
                loss_i_scalar = float(loss_i.item())  # ä»…æ—¥å¿—ç”¨
                if AMP_TRAIN:
                    scaler.scale(0.5 * loss_i).backward()
                else:
                    (0.5 * loss_i).backward()
                del loss_i  # é‡Šæ”¾ Ish çš„è®¡ç®—å›¾ï¼Œé™ä½å³°å€¼æ˜¾å­˜

                # MNIST-AG
                xm28 = xb_m.to(device, non_blocking=True).float()
                ym = yb_m.to(device, non_blocking=True)
                train_seen_epoch += ym.size(0)  # â† MNIST-AG è®¡æ•°
                xm_raw = sample_ag(xm28)
                if epoch==0 and total_updates==0:
                    save_image(xm_raw[0], f"saved_samples/æœªå½’ä¸€åŒ–ep{epoch}_mnist_ag.png")
                    print("ğŸ–¼ï¸ å·²ä¿å­˜ MNIST-AG æ ·ä¾‹å›¾ï¼šsaved_samples/æœªå½’ä¸€åŒ–ep0_mnist_ag.png")

                if args.strategy == 'S2' and args.augmix:
                    with autocast(enabled=AMP_TRAIN):
                        out_m = _apply_augmix_then_norm(
                            xm_raw, model, ym, criterion, args.augmix_jsd,
                            da_module=da_module, da_eps_min=args.da_eps_min, da_eps_max=args.da_eps_max,
                            return_fed=(epoch == 0 and batch_idx == 0),use_ckpt=args.use_ckpt
                        )
                    if isinstance(out_m, tuple):
                        loss_m, fed_m = out_m
                        if epoch == 0 and batch_idx == 0:
                            save_image(fed_m["clean"][0], f"saved_samples/train_ep{epoch}_mnist_ag_clean_input.png")
                            save_image(fed_m["aug1"][0], f"saved_samples/train_ep{epoch}_mnist_ag_aug1_input.png")
                            save_image(fed_m["aug2"][0], f"saved_samples/train_ep{epoch}_mnist_ag_aug2_input.png")
                    else:
                        loss_m = out_m
                else:
                    xm = normalize_imagenet(xm_raw)
                    if da_module is not None:
                        xm = da_module(xm)
                    if epoch == 0 and batch_idx == 0:
                        save_image(xm[0].detach().cpu(), f"saved_samples/train_ep{epoch}_mnist_ag_input.png")
                        print(f"[dump] saved_samples/train_ep{epoch}_mnist_ag_input.png")
                    with autocast(enabled=AMP_TRAIN):
                        logits_m = model(xm)
                        loss_m = criterion(logits_m, ym)

                # ---------------- [IV] å›ä¼  MNIST-AG å¹¶ step ----------------
                loss_m_scalar = float(loss_m.item())
                if AMP_TRAIN:
                    scaler.scale(0.5 * loss_m).backward()
                    scaler.step(optimizer);
                    scaler.update()
                else:
                    (0.5 * loss_m).backward()
                    optimizer.step()
                del loss_m

                # ------- æ—¥å¿—ç´¯è®¡ -------
                loss_scalar = 0.5 * (loss_i_scalar + loss_m_scalar)
                running_loss += loss_scalar
                total_updates += 1


                if (batch_idx + 1) % 50 == 0:
                    print(f"[è®­ç»ƒ:{args.strategy}] epoch={epoch} å·²å¤„ç† {train_seen_epoch} å¼ å›¾åƒï¼ˆIsh + MNIST-AGï¼‰")
        print(f"ğŸ§® [è®­ç»ƒ:{args.strategy}] epoch={epoch} æœ¬è½®è®­ç»ƒå…±ä½¿ç”¨ {train_seen_epoch} å¼ å›¾åƒ")


        # è¯„ä¼°ï¼ˆè‹¥ final_test_only=False åˆ™æ¯è½®éƒ½æµ‹ 6 ä¸ªæµ‹è¯•é›†ï¼Œä»…è®°å½•æ›²çº¿ï¼‰
        if not args.final_test_only:
            test_seen_epoch = 0  # â† æ–°å¢
            subset_accs=[]; epoch_metrics={}
            for name, loader in test_loaders.items():
                acc,nll,ece,xs,ys = evaluate(model, loader, device, name, epoch, save_pic=SAVE_THIS_EPOCH)
                epoch_metrics[name] = dict(acc=acc,nll=nll,ece=ece,xs=xs,ys=ys)
                results_rows.append(dict(epoch=epoch, testset=name, acc=acc, nll=nll, ece=ece,
                                         backbone=args.model_name, strategy=args.strategy, seed=args.seed))
                # â† æ–°å¢ï¼šæŒ‰æ•°æ®é›†å¤§å°è®¡æ•°ï¼ˆä»¥åŸå§‹æ ·æœ¬è®¡ï¼‰
                test_seen_epoch += len(loader.dataset)
            for key in KEY_EVAL: subset_accs.append(epoch_metrics[key]['acc'])
            subset_mean = sum(subset_accs)/len(subset_accs) if subset_accs else 0.0
            dt = time.time()-t0
            ood_text = ", ".join([f"{k}={epoch_metrics[k]['acc']:.4f}" for k in KEY_EVAL])
            print(f"ğŸ“Š [Epoch {epoch}] OODå„é›† acc: {ood_text}")
            print(f"ğŸ“£ [Epoch {epoch}] æ­¥æ•°â‰ˆ{total_updates}, loss={running_loss:.3f}, OODäº”é›†å‡å€¼={subset_mean:.4f}, ç”¨æ—¶={dt:.1f}s")
            # â† æ–°å¢ï¼šæœ¬è½®æµ‹è¯•æ€»é‡
            print(f"ğŸ§ª [æµ‹è¯•] epoch={epoch} æœ¬è½®æµ‹è¯•å…±ä½¿ç”¨ {test_seen_epoch} å¼ å›¾åƒï¼ˆ6 ä¸ªæµ‹è¯•é›†æ€»å’Œï¼‰")
            # æŒ‰ OOD(5) å‡å€¼ä¿å­˜ä¸€ä¸ªâ€œæœ€å¥½ OOD epochâ€çš„å¿«ç…§ï¼ˆä»…è®°å½•ï¼Œä¸å½±å“éªŒè¯é€‰ä¼˜ï¼‰
            if subset_mean > best_subset_mean:
                best_subset_mean = subset_mean; best_epoch = epoch
                os.makedirs(f"best_ood_epoch_{epoch}", exist_ok=True)
                torch.save(_unwrap(model).state_dict(), f"best_ood_epoch_{epoch}/best_weights.pth")
                main._ood_best_epoch = epoch
                main._ood_best_mean = subset_mean

        # ---- éªŒè¯é€‰æ‹©ï¼šIsh_val + AG6(hor/ver) ----
        if args.use_val_selection:
            # Ish_val
            acc_ish_val = _eval_loader_acc(model,
                DataLoader(ish_val, batch_size=64, shuffle=False, num_workers=args.num_workers,
                           pin_memory=True, collate_fn=lambda b: collate_and_to224(b)),
                device, "Ish_val", epoch, save_val_sample=SAVE_THIS_EPOCH)

            # AG6 valï¼ˆhor / verï¼‰
            acc_ag6_h = _eval_loader_acc(model, ag6_hor_val_loader, device, "AG6_hor_val", epoch, save_val_sample=SAVE_THIS_EPOCH)
            acc_ag6_v = _eval_loader_acc(model, ag6_ver_val_loader, device, "AG6_ver_val", epoch, save_val_sample=SAVE_THIS_EPOCH)
            mean_acc_val = (acc_ish_val + acc_ag6_h + acc_ag6_v) / 3.0
            val_imgs_seen_epoch = len(ish_val) \
                                  + len(ag6_hor_val_loader.dataset) \
                                  + len(ag6_ver_val_loader.dataset)
            print(f"ğŸ” [éªŒè¯] epoch={epoch} æœ¬è½®éªŒè¯å…±ä½¿ç”¨ {val_imgs_seen_epoch} å¼ å›¾åƒï¼ˆIsh_val + AG6_hor + AG6_verï¼‰")

            print(f"ğŸ“ [Val] mean_acc_val={mean_acc_val:.4f}")
            if mean_acc_val > getattr(main, "_best_metric", -1e9) + args.min_delta:
                main._best_metric = mean_acc_val
                main._best_epoch_sel = epoch
                torch.save(_unwrap(model).state_dict(), './best.ckpt')
                print(f"ğŸ’¾ éªŒè¯é›†æå‡ï¼Œå·²ä¿å­˜ best.ckptï¼ˆepoch={epoch}ï¼‰")
        else:
            main._best_metric = float("nan")
            main._best_epoch_sel = epoch
            torch.save(_unwrap(model).state_dict(), './best.ckpt')

    # å†™ CSVï¼ˆæ¯è½®æµ‹è¯•æ—¥å¿—ï¼‰
    import csv
    with open(args.results_file, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["epoch","testset","acc","nll","ece","backbone","strategy","seed"])
        writer.writeheader(); writer.writerows(results_rows)
    print(f"ğŸ“„ æŒ‡æ ‡å·²å†™å…¥ {args.results_file}")

    # ===== Final test with best.ckpt =====
    try:
        state = torch.load('./best.ckpt', map_location=device)
        _unwrap(model).load_state_dict(state)
        print(f"âœ… å·²åŠ è½½ best.ckptï¼ˆæ¥è‡ª epoch={getattr(main,'_best_epoch_sel','?')}ï¼Œval_metric={getattr(main,'_best_metric','?')}ï¼‰")
    except Exception as e:
        print("âš ï¸ åŠ è½½ best.ckpt å¤±è´¥ï¼Œæ”¹ç”¨å½“å‰æƒé‡è¿›è¡Œæœ€ç»ˆè¯„æµ‹ï¼š", e)

    # æœ€ç»ˆä¸€æ¬¡ï¼šå…¨é‡å…­ä¸ªæµ‹è¯•é›†ï¼Œè¾“å‡ºæ‰©å±•æŒ‡æ ‡ä¸æ··æ·†çŸ©é˜µ
    out_final = args.final_results_file
    with open(out_final, "w", newline="") as f:
        header = ["ood_epoch","OOD_best_mean","val_epoch","final_best_mean",
                  "testset","acc","nll","ece","macro_precision","macro_recall","macro_f1",
                  "micro_precision","micro_recall","micro_f1"]
        if args.compute_auroc: header.append("auroc_ovr_macro")
        writer = csv.DictWriter(f, fieldnames=header); writer.writeheader()
        os.makedirs("final_cm", exist_ok=True)  # â† æ”¾åœ¨å†™ CSV/CM ä¹‹å‰

        final_rows = []
        ood_names = ["Ishihara", "hor4", "hor8", "ver4", "ver8"]
        ood_accs_tmp = {}

        for name, loader in test_loaders.items():
            model.eval(); all_logits=[]; all_labels=[]
            with torch.no_grad():
                for x,y in loader:
                    x=x.to(device,non_blocking=True); y=y.to(device,non_blocking=True)
                    logits=model(x); all_logits.append(logits.cpu()); all_labels.append(y.cpu())
            logits = torch.cat(all_logits); labels = torch.cat(all_labels)
            acc = float((logits.argmax(1)==labels).float().mean().item())
            nll = negative_log_likelihood(logits, labels).item()
            ece = expected_calibration_error(logits, labels, n_bins=15)
            cm = confusion_matrix_from_logits(logits, labels, num_classes=10)
            prf = prf1_from_confusion_matrix(cm)
            row = dict(testset=name, acc=acc, nll=nll, ece=ece,
                       macro_precision=prf["macro_precision"], macro_recall=prf["macro_recall"], macro_f1=prf["macro_f1"],
                       micro_precision=prf["micro_precision"], micro_recall=prf["micro_recall"], micro_f1=prf["micro_f1"])
            if args.compute_auroc:
                auc = auroc_one_vs_rest(logits, labels)
                row["auroc_ovr_macro"] = auc if auc is not None else ""

            save_confusion_matrix_png(cm, f"final_cm/{name}_cm.png")
            save_matrix_csv(cm, f"final_cm/{name}_cm.csv")
            # æ”¶é›† OOD5 acc
            if name in ood_names:
                ood_accs_tmp[name] = acc

            final_rows.append(row)

        # è®¡ç®—æœ€ç»ˆï¼ˆbest.ckpt ä¸‹ï¼‰OOD5 äº”é›†çš„å‡å€¼
        final_best_mean = (sum(ood_accs_tmp.values()) / len(ood_accs_tmp)) if ood_accs_tmp else float("nan")

        # å–å‡ºä¸¤ä¸ª epoch æŒ‡æ ‡ï¼šè®­ç»ƒæœŸ OOD-best ä¸ éªŒè¯é€‰ä¼˜çš„ best.ckpt epoch
        ood_epoch = getattr(main, "_ood_best_epoch", "")
        ood_best_mean = getattr(main, "_ood_best_mean", "")
        val_epoch = getattr(main, "_best_epoch_sel", "")

        # ç¬¬äºŒéï¼šæŠŠå››ä¸ªå‰ç½®å­—æ®µå¡«è¿›å»ï¼Œå†å†™æ¯ä¸€è¡Œ
        for row in final_rows:
            row_out = dict(
                ood_epoch=ood_epoch,
                OOD_best_mean=ood_best_mean,
                val_epoch=val_epoch,
                final_best_mean=final_best_mean,
            )
            row_out.update(row)
            writer.writerow(row_out)

    print(f"ğŸ“„ å·²è¾“å‡ºæœ€ç»ˆç»“æœåˆ° {out_final}ï¼Œå¹¶ä¿å­˜æ··æ·†çŸ©é˜µåˆ° final_cm/")

if __name__ == "__main__":
    main()